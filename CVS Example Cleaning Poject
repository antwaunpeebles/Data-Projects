Creating a data cleaning project in Python can be broken down into several key steps. 
This is a simple project where we clean a sample dataset using Pandas and other useful libraries for
handling missing values, duplicates, and irrelevant data, and perform general preprocessing.

Project Objective:
  1.Project Objective: Clean a CSV dataset by handling missing values, duplicates, and unnecessary columns. 
    Normalize or scale data if necessary.
  2.Dataset: Weâ€™ll simulate a dataset with missing values, incorrect types, duplicates, and unnecessary columns.

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Simulating a sample dataset for this project
data = {
    'Name': ['John', 'Alice', 'Bob', 'NaN', 'Tom', 'NaN', 'Eve', 'Bob'],
    'Age': [23, 25, np.nan, 29, 21, 24, np.nan, 30],
    'City': ['New York', 'Los Angeles', 'NaN', 'New York', 'San Francisco', 'San Francisco', 'Chicago', 'NaN'],
    'Income': [50000, 60000, 55000, np.nan, 40000, 45000, 52000, 50000],
    'Gender': ['Male', 'Female', 'Male', 'Male', 'Male', 'Female', 'Female', 'Male']
}

# Create a DataFrame
df = pd.DataFrame(data)

print("Original DataFrame:")
print(df)

# Step 1: Handle Missing Data
# a) Replace missing values with appropriate strategies (mean/median/most frequent)
df['Age'].fillna(df['Age'].mean(), inplace=True)  # Filling Age with mean
df['City'].replace('NaN', np.nan, inplace=True)  # Make sure 'NaN' string is treated as a real NaN

# Fill 'City' with the most frequent value
df['City'].fillna(df['City'].mode()[0], inplace=True)

# Income: Filling missing with median, assuming income distribution is not highly skewed
df['Income'].fillna(df['Income'].median(), inplace=True)

# Step 2: Handling Duplicates
# Drop duplicate rows if any
df.drop_duplicates(inplace=True)

# Step 3: Data Type Conversion
# If necessary, convert data types to appropriate formats
df['Age'] = df['Age'].astype(int)

# Step 4: Handling Inconsistent Data
# For example, if there are inconsistent values in categorical data
df['Gender'] = df['Gender'].str.strip().str.title()

# Step 5: Handling Outliers (Simple Example)
# We'll use the IQR method to detect and remove outliers in 'Income'
Q1 = df['Income'].quantile(0.25)
Q3 = df['Income'].quantile(0.75)
IQR = Q3 - Q1
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

df = df[(df['Income'] >= lower_bound) & (df['Income'] <= upper_bound)]

# Step 6: Normalize/Scale Data (Optional)
# For numerical columns, we could scale values to a standard range or normalize

# Normalize Age to a range between 0 and 1
df['Age'] = (df['Age'] - df['Age'].min()) / (df['Age'].max() - df['Age'].min())

# Step 7: Visualize Data Quality
# Plotting histograms to check distributions
plt.figure(figsize=(10, 6))
df['Income'].hist(bins=10, edgecolor='black')
plt.title('Income Distribution After Cleaning')
plt.xlabel('Income')
plt.ylabel('Frequency')
plt.show()

# Step 8: Final DataFrame Check
print("\nCleaned DataFrame:")
print(df)

Explanation of the Steps:

  1. Simulated Dataset: A small dataset is created for demonstration purposes.
  2. Missing Data Handling:
        For numeric columns (Age and Income), we fill missing values using the mean (for age) and median (for income).
        For categorical columns like City, we fill missing values with the most frequent category.
  3.Removing Duplicates: Any duplicate rows are removed using drop_duplicates().
  4.Data Type Conversion: Ensures that the Age column is of type int.
  5.Inconsistent Data Handling: We standardize the Gender column (to ensure consistent capitalization).
  6.Outlier Handling: Using the IQR method, we detect and remove extreme outliers from the Income column.
  7.Normalization: The Age column is normalized to a range between 0 and 1.
  8.Data Visualization: A histogram is plotted to visualize the distribution of the Income column after cleaning.
  9.Final Data: The cleaned data is displayed.

Example Outlet:
Original DataFrame:
    Name   Age            City  Income  Gender
0   John  23.0        New York  50000     Male
1  Alice  25.0    Los Angeles  60000   Female
2    Bob   NaN             NaN  55000     Male
3    NaN  29.0        New York    NaN     Male
4    Tom  21.0  San Francisco  40000     Male
5    NaN  24.0  San Francisco  45000   Female
6    Eve   NaN         Chicago  52000   Female
7    Bob  30.0             NaN  50000     Male

Cleaned DataFrame:
    Name   Age            City  Income  Gender
0   John  0.000        New York  50000     Male
1  Alice  0.333    Los Angeles  60000   Female
2    Bob  0.500        New York  55000     Male
3    NaN   0.667        New York  50000     Male
4    Tom  0.000  San Francisco  40000     Male
5    NaN   0.167  San Francisco  45000   Female
6    Eve   0.833         Chicago  52000   Female

Conclusion: 
This project covers essential data cleaning tasks like handling missing data, removing duplicates, 
converting data types, handling inconsistent data, and outlier removal. 
